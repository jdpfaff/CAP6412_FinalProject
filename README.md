# CAP6412_FinalProject
Vision transformers have taken the world of Computer Vision by storm since the start of 2020’s, being one of the most researched areas in the field. Despite this, there are some shortcomings to vision transformers. For one, they struggle to correctly identify and segment smaller images in general, and also require very large datasets in order to be trained, requiring a large amount of resources and power in order to effectively. We conducted a study in which we attempt to modify a vision transformer with semantic segmentation to detect smaller, similar images, in our case, cells, and isn’t hampered by the fact that the dataset is small. Results would then compared with convolutional networks through a masked R-CNN model, giving a good reference point to what kinds of accuracy can be achieved on this type of dataset and what we aim to surpass.
